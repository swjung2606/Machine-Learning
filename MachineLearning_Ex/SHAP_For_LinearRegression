# -*- coding: utf-8 -*-
"""
Created on Mon Jan 16 08:03:52 2023

@author: sunjung
"""


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
import shap


dict_data = {'x' : [1,1,1,2,2,2,3,3,3] , 'y' : [1,2,3,1,2,3,1,2,3] , 'z' : [1.59,0.47, -0.53, 3.07, 2.1, 0.87, 4.39, 3.51, 2.57]}
df = pd.DataFrame(dict_data)

# XX : features , yy : dependent variable (Target)
XX = df[['x','y']].values
yy = df['z'].values

# a + bx + cy model
poly1 = PolynomialFeatures(degree=2)
X_poly1 = pd.DataFrame(poly1.fit_transform(XX))

# fitting
model = LinearRegression()
model.fit(XX,yy)

# SHAP computation & Visualization
shap.initjs()
explainer = shap.LinearExplainer(model, XX)
shap_values = explainer.shap_values(XX)
